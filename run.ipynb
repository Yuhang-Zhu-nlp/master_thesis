{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkMyrQSMHNXn",
        "outputId": "99346adc-a77d-4adc-aa32-41fe6bc12ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'master_thesis'...\n",
            "remote: Enumerating objects: 238, done.\u001b[K\n",
            "remote: Counting objects: 100% (238/238), done.\u001b[K\n",
            "remote: Compressing objects: 100% (170/170), done.\u001b[K\n",
            "remote: Total 238 (delta 116), reused 180 (delta 63), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (238/238), 3.36 MiB | 3.84 MiB/s, done.\n",
            "Resolving deltas: 100% (116/116), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Yuhang-Zhu-nlp/master_thesis.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrL-GRZxLOJi",
        "outputId": "1c4ef2d2-90ac-41b5-cb65-dda9064388b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/297.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m276.5/297.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.29.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!wandb login"
      ],
      "metadata": {
        "id": "DIJw-Acx_rYW",
        "outputId": "be656da5-7a33-4fca-c7e8-6ff09c22ba03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.45.0-py2.py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.45.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0oq58mihQAfm",
        "outputId": "c3b6ae35-916d-417a-87f8-d3d2b9fffc16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python master_thesis/operation/train.py \\\n",
        "            --pos_path_train '/content/master_thesis/data/en_train_fut_pos.json' \\\n",
        "            --neg_path_train '/content/master_thesis/data/en_train_fut_neg.json' \\\n",
        "            --pos_path_dev '/content/master_thesis/data/en_dev_fut_pos.json' \\\n",
        "            --neg_path_dev '/content/master_thesis/data/en_dev_fut_neg.json' \\\n",
        "            --model_name 'en_bert' \\\n",
        "            --pool_method 'layer_weight_sum_word' \\\n",
        "            --learning_rate 5e-4 \\\n",
        "            --weight_decay 0.01 \\\n",
        "            --batch_size_train 32 \\\n",
        "            --batch_size_valid 32 \\\n",
        "            --epoch 30 \\\n",
        "            --warmup_steps 100 \\\n",
        "            --checkpoints_dir '/content/checkpoints/en_sp_word_layer14'\\\n",
        "            --output_dir '/content/drive/MyDrive/master_thesis/en_sp/en_sp_word_layer14.pt'\\\n",
        "            --layer 14 \\\n",
        "            --is_wandb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCX-ReP8Ho8V",
        "outputId": "cc5fabbb-a5f2-467c-9f57-a6b9d515fbf1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-16 22:00:22.175807: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-16 22:00:22.175862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-16 22:00:22.177490: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-16 22:00:23.308896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzhuyuhang737\u001b[0m (\u001b[33mmaster_thesis_johan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20240416_220033-nqbnkero\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbrisk-haze-114\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/master_thesis_johan/master_thesis_johan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/master_thesis_johan/master_thesis_johan/runs/nqbnkero\u001b[0m\n",
            "english_bert(\n",
            "  (_classfier_module__bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 1024)\n",
            "      (token_type_embeddings): Embedding(2, 1024)\n",
            "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-23): 24 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (_classfier_module__classifier_head): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "    (1): Linear(in_features=2048, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "size of training set: 2000\n",
            "size of validation set: 272\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "{'loss': 0.6963, 'grad_norm': 0.6401323676109314, 'learning_rate': 5e-06, 'epoch': 0.13}\n",
            "{'loss': 0.696, 'grad_norm': 0.521233320236206, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
            "{'loss': 0.6959, 'grad_norm': 0.48410147428512573, 'learning_rate': 1.5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.6894, 'grad_norm': 0.46454110741615295, 'learning_rate': 2e-05, 'epoch': 0.51}\n",
            "{'loss': 0.6918, 'grad_norm': 0.6757853627204895, 'learning_rate': 2.5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.683, 'grad_norm': 0.8092134594917297, 'learning_rate': 3e-05, 'epoch': 0.76}\n",
            "{'loss': 0.6771, 'grad_norm': 0.47770094871520996, 'learning_rate': 3.5000000000000004e-05, 'epoch': 0.89}\n",
            "  3% 7/210 [00:12<05:49,  1.72s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.98it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.83it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.42it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.91it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.62it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.96it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.6709021925926208, 'eval_f1': 0.7299270072992701, 'eval_precision': 0.7246376811594203, 'eval_recall': 0.7352941176470589, 'eval_runtime': 1.5362, 'eval_samples_per_second': 177.066, 'eval_steps_per_second': 5.859, 'epoch': 0.89}\n",
            "  3% 7/210 [00:15<05:49,  1.72s/it]\n",
            "100% 9/9 [00:01<00:00,  6.27it/s]\u001b[A\n",
            "{'loss': 0.6716, 'grad_norm': 0.8140375018119812, 'learning_rate': 4e-05, 'epoch': 1.02}\n",
            "{'loss': 0.663, 'grad_norm': 0.7229878902435303, 'learning_rate': 4.4999999999999996e-05, 'epoch': 1.14}\n",
            "{'loss': 0.6575, 'grad_norm': 0.980140209197998, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.6493, 'grad_norm': 0.4407953917980194, 'learning_rate': 5.5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.6349, 'grad_norm': 0.7487496733665466, 'learning_rate': 6e-05, 'epoch': 1.52}\n",
            "{'loss': 0.6127, 'grad_norm': 0.5000653862953186, 'learning_rate': 6.500000000000001e-05, 'epoch': 1.65}\n",
            "{'loss': 0.6115, 'grad_norm': 0.44672173261642456, 'learning_rate': 7.000000000000001e-05, 'epoch': 1.78}\n",
            "{'loss': 0.5943, 'grad_norm': 0.4695514440536499, 'learning_rate': 7.5e-05, 'epoch': 1.9}\n",
            "  7% 15/210 [00:32<05:40,  1.75s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.98it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.80it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.38it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.93it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.60it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.91it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.5880274772644043, 'eval_f1': 0.8048780487804877, 'eval_precision': 0.6875, 'eval_recall': 0.9705882352941176, 'eval_runtime': 1.5421, 'eval_samples_per_second': 176.386, 'eval_steps_per_second': 5.836, 'epoch': 1.9}\n",
            "  7% 15/210 [00:34<05:40,  1.75s/it]\n",
            "100% 9/9 [00:01<00:00,  6.22it/s]\u001b[A\n",
            "{'loss': 0.6026, 'grad_norm': 0.8502737879753113, 'learning_rate': 8e-05, 'epoch': 2.03}\n",
            "{'loss': 0.5764, 'grad_norm': 0.5806639194488525, 'learning_rate': 8.5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.564, 'grad_norm': 0.4049869179725647, 'learning_rate': 8.999999999999999e-05, 'epoch': 2.29}\n",
            "{'loss': 0.5757, 'grad_norm': 0.8805994391441345, 'learning_rate': 9.5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.5437, 'grad_norm': 0.3696678876876831, 'learning_rate': 0.0001, 'epoch': 2.54}\n",
            "{'loss': 0.5308, 'grad_norm': 0.47095948457717896, 'learning_rate': 0.000105, 'epoch': 2.67}\n",
            "{'loss': 0.5223, 'grad_norm': 0.5668757557868958, 'learning_rate': 0.00011, 'epoch': 2.79}\n",
            "{'loss': 0.5052, 'grad_norm': 0.5327600836753845, 'learning_rate': 0.000115, 'epoch': 2.92}\n",
            " 11% 23/210 [00:52<05:55,  1.90s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.85it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.76it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.32it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.91it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.62it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.93it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.4910529553890228, 'eval_f1': 0.8466666666666667, 'eval_precision': 0.774390243902439, 'eval_recall': 0.9338235294117647, 'eval_runtime': 1.5457, 'eval_samples_per_second': 175.974, 'eval_steps_per_second': 5.823, 'epoch': 2.92}\n",
            " 11% 23/210 [00:54<05:55,  1.90s/it]\n",
            "100% 9/9 [00:01<00:00,  6.26it/s]\u001b[A\n",
            "{'loss': 0.4861, 'grad_norm': 1.0438669919967651, 'learning_rate': 0.00012, 'epoch': 3.05}\n",
            "{'loss': 0.5049, 'grad_norm': 0.4407489001750946, 'learning_rate': 0.000125, 'epoch': 3.17}\n",
            "{'loss': 0.4646, 'grad_norm': 0.45337459444999695, 'learning_rate': 0.00013000000000000002, 'epoch': 3.3}\n",
            "{'loss': 0.4872, 'grad_norm': 0.3721577823162079, 'learning_rate': 0.000135, 'epoch': 3.43}\n",
            "{'loss': 0.4723, 'grad_norm': 0.5587575435638428, 'learning_rate': 0.00014000000000000001, 'epoch': 3.56}\n",
            "{'loss': 0.4474, 'grad_norm': 0.39545688033103943, 'learning_rate': 0.000145, 'epoch': 3.68}\n",
            "{'loss': 0.4389, 'grad_norm': 0.3885599374771118, 'learning_rate': 0.00015, 'epoch': 3.81}\n",
            "{'loss': 0.4539, 'grad_norm': 0.6600213646888733, 'learning_rate': 0.000155, 'epoch': 3.94}\n",
            " 15% 31/210 [01:12<05:53,  1.97s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.83it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.65it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.24it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.83it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.54it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.88it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.40886351466178894, 'eval_f1': 0.8762541806020068, 'eval_precision': 0.803680981595092, 'eval_recall': 0.9632352941176471, 'eval_runtime': 1.5612, 'eval_samples_per_second': 174.222, 'eval_steps_per_second': 5.765, 'epoch': 3.94}\n",
            " 15% 31/210 [01:14<05:53,  1.97s/it]\n",
            "100% 9/9 [00:01<00:00,  6.17it/s]\u001b[A\n",
            "{'loss': 0.3854, 'grad_norm': 0.5054691433906555, 'learning_rate': 0.00016, 'epoch': 4.06}\n",
            "{'loss': 0.4171, 'grad_norm': 0.37168729305267334, 'learning_rate': 0.000165, 'epoch': 4.19}\n",
            "{'loss': 0.393, 'grad_norm': 0.3849290907382965, 'learning_rate': 0.00017, 'epoch': 4.32}\n",
            "{'loss': 0.4055, 'grad_norm': 0.3420860171318054, 'learning_rate': 0.000175, 'epoch': 4.44}\n",
            "{'loss': 0.4148, 'grad_norm': 0.55653977394104, 'learning_rate': 0.00017999999999999998, 'epoch': 4.57}\n",
            "{'loss': 0.3736, 'grad_norm': 0.4091431200504303, 'learning_rate': 0.000185, 'epoch': 4.7}\n",
            "{'loss': 0.3919, 'grad_norm': 0.4263395667076111, 'learning_rate': 0.00019, 'epoch': 4.83}\n",
            "{'loss': 0.3783, 'grad_norm': 0.5190897583961487, 'learning_rate': 0.00019500000000000002, 'epoch': 4.95}\n",
            " 19% 39/210 [01:31<05:36,  1.97s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.75it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.66it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.25it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.82it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.53it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.87it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.3406184911727905, 'eval_f1': 0.9034482758620689, 'eval_precision': 0.8506493506493507, 'eval_recall': 0.9632352941176471, 'eval_runtime': 1.567, 'eval_samples_per_second': 173.576, 'eval_steps_per_second': 5.743, 'epoch': 4.95}\n",
            " 19% 39/210 [01:33<05:36,  1.97s/it]\n",
            "100% 9/9 [00:01<00:00,  6.16it/s]\u001b[A\n",
            "{'loss': 0.3319, 'grad_norm': 0.6331021189689636, 'learning_rate': 0.0002, 'epoch': 5.08}\n",
            "{'loss': 0.351, 'grad_norm': 0.34264683723449707, 'learning_rate': 0.000205, 'epoch': 5.21}\n",
            "{'loss': 0.3736, 'grad_norm': 0.26289069652557373, 'learning_rate': 0.00021, 'epoch': 5.33}\n",
            "{'loss': 0.3397, 'grad_norm': 0.3090212941169739, 'learning_rate': 0.000215, 'epoch': 5.46}\n",
            "{'loss': 0.3345, 'grad_norm': 0.3493337035179138, 'learning_rate': 0.00022, 'epoch': 5.59}\n",
            "{'loss': 0.2711, 'grad_norm': 0.34918051958084106, 'learning_rate': 0.00022500000000000002, 'epoch': 5.71}\n",
            "{'loss': 0.2958, 'grad_norm': 0.36265793442726135, 'learning_rate': 0.00023, 'epoch': 5.84}\n",
            "{'loss': 0.3405, 'grad_norm': 0.21919958293437958, 'learning_rate': 0.000235, 'epoch': 5.97}\n",
            " 22% 47/210 [01:51<05:13,  1.92s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.66it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.54it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.20it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.77it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.49it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.82it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.2865225374698639, 'eval_f1': 0.9097222222222222, 'eval_precision': 0.8618421052631579, 'eval_recall': 0.9632352941176471, 'eval_runtime': 1.5819, 'eval_samples_per_second': 171.941, 'eval_steps_per_second': 5.689, 'epoch': 5.97}\n",
            " 22% 47/210 [01:53<05:13,  1.92s/it]\n",
            "100% 9/9 [00:01<00:00,  6.09it/s]\u001b[A\n",
            "{'loss': 0.3187, 'grad_norm': 0.19991275668144226, 'learning_rate': 0.00024, 'epoch': 6.1}\n",
            "{'loss': 0.3338, 'grad_norm': 0.850481390953064, 'learning_rate': 0.000245, 'epoch': 6.22}\n",
            "{'loss': 0.3039, 'grad_norm': 0.2649472653865814, 'learning_rate': 0.00025, 'epoch': 6.35}\n",
            "{'loss': 0.2905, 'grad_norm': 0.41601845622062683, 'learning_rate': 0.000255, 'epoch': 6.48}\n",
            "{'loss': 0.3124, 'grad_norm': 0.6817042231559753, 'learning_rate': 0.00026000000000000003, 'epoch': 6.6}\n",
            "{'loss': 0.2843, 'grad_norm': 0.5956867337226868, 'learning_rate': 0.00026500000000000004, 'epoch': 6.73}\n",
            "{'loss': 0.2556, 'grad_norm': 0.5587008595466614, 'learning_rate': 0.00027, 'epoch': 6.86}\n",
            "{'loss': 0.2825, 'grad_norm': 0.19456884264945984, 'learning_rate': 0.000275, 'epoch': 6.98}\n",
            " 26% 55/210 [02:11<04:47,  1.86s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.77it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.63it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.27it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.83it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.54it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.85it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.24297507107257843, 'eval_f1': 0.9204152249134947, 'eval_precision': 0.869281045751634, 'eval_recall': 0.9779411764705882, 'eval_runtime': 1.5702, 'eval_samples_per_second': 173.226, 'eval_steps_per_second': 5.732, 'epoch': 6.98}\n",
            " 26% 55/210 [02:13<04:47,  1.86s/it]\n",
            "100% 9/9 [00:01<00:00,  6.10it/s]\u001b[A\n",
            "{'loss': 0.2349, 'grad_norm': 0.47047775983810425, 'learning_rate': 0.00028000000000000003, 'epoch': 7.11}\n",
            "{'loss': 0.2769, 'grad_norm': 0.4972868859767914, 'learning_rate': 0.000285, 'epoch': 7.24}\n",
            "{'loss': 0.2296, 'grad_norm': 0.610576868057251, 'learning_rate': 0.00029, 'epoch': 7.37}\n",
            "{'loss': 0.2735, 'grad_norm': 0.9165847897529602, 'learning_rate': 0.000295, 'epoch': 7.49}\n",
            "{'loss': 0.3191, 'grad_norm': 1.063480257987976, 'learning_rate': 0.0003, 'epoch': 7.62}\n",
            "{'loss': 0.265, 'grad_norm': 0.25263985991477966, 'learning_rate': 0.000305, 'epoch': 7.75}\n",
            "{'loss': 0.2452, 'grad_norm': 0.23752206563949585, 'learning_rate': 0.00031, 'epoch': 7.87}\n",
            "{'loss': 0.2299, 'grad_norm': 1.19652259349823, 'learning_rate': 0.000315, 'epoch': 8.0}\n",
            " 30% 63/210 [02:31<04:43,  1.93s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.74it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.66it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.29it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.83it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.50it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.84it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.22106294333934784, 'eval_f1': 0.9172932330827067, 'eval_precision': 0.9384615384615385, 'eval_recall': 0.8970588235294118, 'eval_runtime': 1.5713, 'eval_samples_per_second': 173.102, 'eval_steps_per_second': 5.728, 'epoch': 8.0}\n",
            " 30% 63/210 [02:33<04:43,  1.93s/it]\n",
            "100% 9/9 [00:01<00:00,  6.09it/s]\u001b[A\n",
            "{'loss': 0.2576, 'grad_norm': 1.3675225973129272, 'learning_rate': 0.00032, 'epoch': 8.13}\n",
            "{'loss': 0.2612, 'grad_norm': 0.5414336919784546, 'learning_rate': 0.00032500000000000004, 'epoch': 8.25}\n",
            "{'loss': 0.2114, 'grad_norm': 0.46520286798477173, 'learning_rate': 0.00033, 'epoch': 8.38}\n",
            "{'loss': 0.2382, 'grad_norm': 0.28989315032958984, 'learning_rate': 0.000335, 'epoch': 8.51}\n",
            "{'loss': 0.1993, 'grad_norm': 0.3450480103492737, 'learning_rate': 0.00034, 'epoch': 8.63}\n",
            "{'loss': 0.2034, 'grad_norm': 0.45657917857170105, 'learning_rate': 0.000345, 'epoch': 8.76}\n",
            "{'loss': 0.2703, 'grad_norm': 1.0445377826690674, 'learning_rate': 0.00035, 'epoch': 8.89}\n",
            " 33% 70/210 [02:50<04:56,  2.12s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.88it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.64it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.20it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.75it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.48it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.79it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.1834961622953415, 'eval_f1': 0.9337979094076654, 'eval_precision': 0.8874172185430463, 'eval_recall': 0.9852941176470589, 'eval_runtime': 1.5853, 'eval_samples_per_second': 171.581, 'eval_steps_per_second': 5.677, 'epoch': 8.89}\n",
            " 33% 70/210 [02:53<04:56,  2.12s/it]\n",
            "100% 9/9 [00:01<00:00,  6.09it/s]\u001b[A\n",
            "{'loss': 0.2244, 'grad_norm': 0.5477762222290039, 'learning_rate': 0.000355, 'epoch': 9.02}\n",
            "{'loss': 0.1978, 'grad_norm': 0.1619046926498413, 'learning_rate': 0.00035999999999999997, 'epoch': 9.14}\n",
            "{'loss': 0.2025, 'grad_norm': 0.48741981387138367, 'learning_rate': 0.000365, 'epoch': 9.27}\n",
            "{'loss': 0.2104, 'grad_norm': 0.7695651650428772, 'learning_rate': 0.00037, 'epoch': 9.4}\n",
            "{'loss': 0.1795, 'grad_norm': 0.5541890859603882, 'learning_rate': 0.000375, 'epoch': 9.52}\n",
            "{'loss': 0.2281, 'grad_norm': 0.16238702833652496, 'learning_rate': 0.00038, 'epoch': 9.65}\n",
            "{'loss': 0.2463, 'grad_norm': 0.13390816748142242, 'learning_rate': 0.00038500000000000003, 'epoch': 9.78}\n",
            "{'loss': 0.2075, 'grad_norm': 0.42699190974235535, 'learning_rate': 0.00039000000000000005, 'epoch': 9.9}\n",
            " 37% 78/210 [03:10<04:21,  1.98s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.43it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.39it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.06it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.64it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.26it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.63it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.15894582867622375, 'eval_f1': 0.9571428571428572, 'eval_precision': 0.9305555555555556, 'eval_recall': 0.9852941176470589, 'eval_runtime': 1.6289, 'eval_samples_per_second': 166.985, 'eval_steps_per_second': 5.525, 'epoch': 9.9}\n",
            " 37% 78/210 [03:13<04:21,  1.98s/it]\n",
            "100% 9/9 [00:01<00:00,  5.90it/s]\u001b[A\n",
            "{'loss': 0.1449, 'grad_norm': 0.17497041821479797, 'learning_rate': 0.000395, 'epoch': 10.03}\n",
            "{'loss': 0.2048, 'grad_norm': 0.6457166075706482, 'learning_rate': 0.0004, 'epoch': 10.16}\n",
            "{'loss': 0.1748, 'grad_norm': 0.1602819859981537, 'learning_rate': 0.00040500000000000003, 'epoch': 10.29}\n",
            "{'loss': 0.2133, 'grad_norm': 0.14600692689418793, 'learning_rate': 0.00041, 'epoch': 10.41}\n",
            "{'loss': 0.1651, 'grad_norm': 0.3110378682613373, 'learning_rate': 0.000415, 'epoch': 10.54}\n",
            "{'loss': 0.1749, 'grad_norm': 0.4344169497489929, 'learning_rate': 0.00042, 'epoch': 10.67}\n",
            "{'loss': 0.199, 'grad_norm': 0.3285931646823883, 'learning_rate': 0.000425, 'epoch': 10.79}\n",
            "{'loss': 0.1491, 'grad_norm': 0.33217716217041016, 'learning_rate': 0.00043, 'epoch': 10.92}\n",
            " 41% 86/210 [03:30<04:01,  1.94s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.41it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.38it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.02it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.63it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.34it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.67it/s]\u001b[A\n",
            " 89% 8/9 [00:01<00:00,  5.94it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.14241094887256622, 'eval_f1': 0.9537366548042705, 'eval_precision': 0.9241379310344827, 'eval_recall': 0.9852941176470589, 'eval_runtime': 1.6248, 'eval_samples_per_second': 167.407, 'eval_steps_per_second': 5.539, 'epoch': 10.92}\n",
            " 41% 86/210 [03:32<04:01,  1.94s/it]\n",
            "100% 9/9 [00:01<00:00,  6.79it/s]\u001b[A\n",
            "{'loss': 0.1628, 'grad_norm': 0.2517707943916321, 'learning_rate': 0.000435, 'epoch': 11.05}\n",
            "{'loss': 0.1602, 'grad_norm': 0.4610103368759155, 'learning_rate': 0.00044, 'epoch': 11.17}\n",
            "{'loss': 0.1883, 'grad_norm': 0.7701776623725891, 'learning_rate': 0.00044500000000000003, 'epoch': 11.3}\n",
            "{'loss': 0.1626, 'grad_norm': 0.22907045483589172, 'learning_rate': 0.00045000000000000004, 'epoch': 11.43}\n",
            "{'loss': 0.1593, 'grad_norm': 0.23072557151317596, 'learning_rate': 0.000455, 'epoch': 11.56}\n",
            "{'loss': 0.1266, 'grad_norm': 0.17029155790805817, 'learning_rate': 0.00046, 'epoch': 11.68}\n",
            "{'loss': 0.1592, 'grad_norm': 0.18268339335918427, 'learning_rate': 0.000465, 'epoch': 11.81}\n",
            "{'loss': 0.1603, 'grad_norm': 0.5671018958091736, 'learning_rate': 0.00047, 'epoch': 11.94}\n",
            " 45% 94/210 [03:50<03:35,  1.86s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.42it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.46it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.13it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.70it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.40it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.72it/s]\u001b[A\n",
            " 89% 8/9 [00:01<00:00,  6.02it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.13321278989315033, 'eval_f1': 0.9667896678966789, 'eval_precision': 0.9703703703703703, 'eval_recall': 0.9632352941176471, 'eval_runtime': 1.6082, 'eval_samples_per_second': 169.136, 'eval_steps_per_second': 5.596, 'epoch': 11.94}\n",
            " 45% 94/210 [03:52<03:35,  1.86s/it]\n",
            "100% 9/9 [00:01<00:00,  6.87it/s]\u001b[A\n",
            "{'loss': 0.1426, 'grad_norm': 0.5464540123939514, 'learning_rate': 0.000475, 'epoch': 12.06}\n",
            "{'loss': 0.1921, 'grad_norm': 0.4670599102973938, 'learning_rate': 0.00048, 'epoch': 12.19}\n",
            "{'loss': 0.148, 'grad_norm': 0.12081988900899887, 'learning_rate': 0.00048499999999999997, 'epoch': 12.32}\n",
            "{'loss': 0.1281, 'grad_norm': 0.15247757732868195, 'learning_rate': 0.00049, 'epoch': 12.44}\n",
            "{'loss': 0.1731, 'grad_norm': 0.18248403072357178, 'learning_rate': 0.000495, 'epoch': 12.57}\n",
            "{'loss': 0.1193, 'grad_norm': 0.36482125520706177, 'learning_rate': 0.0005, 'epoch': 12.7}\n",
            "{'loss': 0.1271, 'grad_norm': 0.1552935689687729, 'learning_rate': 0.0004954545454545455, 'epoch': 12.83}\n",
            "{'loss': 0.1362, 'grad_norm': 0.19473892450332642, 'learning_rate': 0.0004909090909090909, 'epoch': 12.95}\n",
            " 49% 102/210 [04:10<03:24,  1.90s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.51it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.44it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.16it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.74it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.43it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.74it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.1215643584728241, 'eval_f1': 0.96, 'eval_precision': 0.9496402877697842, 'eval_recall': 0.9705882352941176, 'eval_runtime': 1.6018, 'eval_samples_per_second': 169.805, 'eval_steps_per_second': 5.619, 'epoch': 12.95}\n",
            " 49% 102/210 [04:12<03:24,  1.90s/it]\n",
            "100% 9/9 [00:01<00:00,  6.04it/s]\u001b[A\n",
            "{'loss': 0.1703, 'grad_norm': 0.2560589611530304, 'learning_rate': 0.0004863636363636364, 'epoch': 13.08}\n",
            "{'loss': 0.1385, 'grad_norm': 0.5334250330924988, 'learning_rate': 0.00048181818181818184, 'epoch': 13.21}\n",
            "{'loss': 0.1197, 'grad_norm': 0.2845076322555542, 'learning_rate': 0.0004772727272727273, 'epoch': 13.33}\n",
            "{'loss': 0.1508, 'grad_norm': 0.44199684262275696, 'learning_rate': 0.0004727272727272727, 'epoch': 13.46}\n",
            "{'loss': 0.1369, 'grad_norm': 0.23020483553409576, 'learning_rate': 0.0004681818181818182, 'epoch': 13.59}\n",
            "{'loss': 0.1647, 'grad_norm': 0.6653035283088684, 'learning_rate': 0.00046363636363636366, 'epoch': 13.71}\n",
            "{'loss': 0.1182, 'grad_norm': 0.34211307764053345, 'learning_rate': 0.0004590909090909091, 'epoch': 13.84}\n",
            "{'loss': 0.1008, 'grad_norm': 0.1498512327671051, 'learning_rate': 0.00045454545454545455, 'epoch': 13.97}\n",
            " 52% 110/210 [04:31<03:14,  1.94s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.44it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.48it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.11it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.74it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.45it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.75it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.11014123260974884, 'eval_f1': 0.9640287769784172, 'eval_precision': 0.9436619718309859, 'eval_recall': 0.9852941176470589, 'eval_runtime': 1.6016, 'eval_samples_per_second': 169.826, 'eval_steps_per_second': 5.619, 'epoch': 13.97}\n",
            " 52% 110/210 [04:32<03:14,  1.94s/it]\n",
            "100% 9/9 [00:01<00:00,  6.02it/s]\u001b[A\n",
            "{'loss': 0.1006, 'grad_norm': 0.39900317788124084, 'learning_rate': 0.00045000000000000004, 'epoch': 14.1}\n",
            "{'loss': 0.1569, 'grad_norm': 0.11707311868667603, 'learning_rate': 0.00044545454545454543, 'epoch': 14.22}\n",
            "{'loss': 0.1112, 'grad_norm': 0.8786306381225586, 'learning_rate': 0.00044090909090909093, 'epoch': 14.35}\n",
            "{'loss': 0.1253, 'grad_norm': 0.27477091550827026, 'learning_rate': 0.00043636363636363637, 'epoch': 14.48}\n",
            "{'loss': 0.1113, 'grad_norm': 0.38710635900497437, 'learning_rate': 0.0004318181818181818, 'epoch': 14.6}\n",
            "{'loss': 0.1, 'grad_norm': 0.11703170835971832, 'learning_rate': 0.00042727272727272726, 'epoch': 14.73}\n",
            "{'loss': 0.123, 'grad_norm': 0.32839563488960266, 'learning_rate': 0.00042272727272727275, 'epoch': 14.86}\n",
            "{'loss': 0.1066, 'grad_norm': 0.2585512399673462, 'learning_rate': 0.00041818181818181814, 'epoch': 14.98}\n",
            " 56% 118/210 [04:49<02:54,  1.90s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.33it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.50it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.09it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.68it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.36it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.72it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.11531850695610046, 'eval_f1': 0.9469964664310954, 'eval_precision': 0.9115646258503401, 'eval_recall': 0.9852941176470589, 'eval_runtime': 1.6149, 'eval_samples_per_second': 168.426, 'eval_steps_per_second': 5.573, 'epoch': 14.98}\n",
            " 56% 118/210 [04:51<02:54,  1.90s/it]\n",
            "100% 9/9 [00:01<00:00,  5.99it/s]\u001b[A\n",
            "{'loss': 0.1081, 'grad_norm': 0.42671453952789307, 'learning_rate': 0.00041363636363636364, 'epoch': 15.11}\n",
            "{'loss': 0.1253, 'grad_norm': 0.7017772197723389, 'learning_rate': 0.00040909090909090913, 'epoch': 15.24}\n",
            "{'loss': 0.1014, 'grad_norm': 0.13703712821006775, 'learning_rate': 0.0004045454545454546, 'epoch': 15.37}\n",
            "{'loss': 0.0989, 'grad_norm': 0.37918031215667725, 'learning_rate': 0.0004, 'epoch': 15.49}\n",
            "{'loss': 0.1231, 'grad_norm': 0.7307029366493225, 'learning_rate': 0.00039545454545454546, 'epoch': 15.62}\n",
            "{'loss': 0.1128, 'grad_norm': 0.2909272313117981, 'learning_rate': 0.00039090909090909096, 'epoch': 15.75}\n",
            "{'loss': 0.0957, 'grad_norm': 0.0967644676566124, 'learning_rate': 0.00038636363636363635, 'epoch': 15.87}\n",
            "{'loss': 0.1078, 'grad_norm': 0.09180047363042831, 'learning_rate': 0.00038181818181818184, 'epoch': 16.0}\n",
            " 60% 126/210 [05:10<02:35,  1.85s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.61it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.47it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.13it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.70it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.37it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.68it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.10464902222156525, 'eval_f1': 0.9675090252707582, 'eval_precision': 0.950354609929078, 'eval_recall': 0.9852941176470589, 'eval_runtime': 1.6167, 'eval_samples_per_second': 168.241, 'eval_steps_per_second': 5.567, 'epoch': 16.0}\n",
            " 60% 126/210 [05:11<02:35,  1.85s/it]\n",
            "100% 9/9 [00:01<00:00,  5.94it/s]\u001b[A\n",
            "{'loss': 0.114, 'grad_norm': 0.36784327030181885, 'learning_rate': 0.0003772727272727273, 'epoch': 16.13}\n",
            "{'loss': 0.1002, 'grad_norm': 0.1733608990907669, 'learning_rate': 0.00037272727272727273, 'epoch': 16.25}\n",
            "{'loss': 0.1051, 'grad_norm': 0.422922819852829, 'learning_rate': 0.00036818181818181817, 'epoch': 16.38}\n",
            "{'loss': 0.1099, 'grad_norm': 0.25034454464912415, 'learning_rate': 0.00036363636363636367, 'epoch': 16.51}\n",
            "{'loss': 0.1037, 'grad_norm': 0.15855535864830017, 'learning_rate': 0.00035909090909090906, 'epoch': 16.63}\n",
            "{'loss': 0.125, 'grad_norm': 0.14787781238555908, 'learning_rate': 0.00035454545454545455, 'epoch': 16.76}\n",
            "{'loss': 0.1027, 'grad_norm': 0.4189664125442505, 'learning_rate': 0.00035, 'epoch': 16.89}\n",
            " 63% 133/210 [05:29<02:36,  2.04s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.48it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.44it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.10it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.69it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.36it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.68it/s]\u001b[A\n",
            " 89% 8/9 [00:01<00:00,  5.97it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.10459935665130615, 'eval_f1': 0.959409594095941, 'eval_precision': 0.9629629629629629, 'eval_recall': 0.9558823529411765, 'eval_runtime': 1.6216, 'eval_samples_per_second': 167.731, 'eval_steps_per_second': 5.55, 'epoch': 16.89}\n",
            " 63% 133/210 [05:32<02:36,  2.04s/it]\n",
            "100% 9/9 [00:01<00:00,  6.78it/s]\u001b[A\n",
            "{'loss': 0.0903, 'grad_norm': 0.16371366381645203, 'learning_rate': 0.00034545454545454544, 'epoch': 17.02}\n",
            "{'loss': 0.0978, 'grad_norm': 0.18571162223815918, 'learning_rate': 0.0003409090909090909, 'epoch': 17.14}\n",
            "{'loss': 0.0991, 'grad_norm': 0.22177307307720184, 'learning_rate': 0.0003363636363636364, 'epoch': 17.27}\n",
            "{'loss': 0.0881, 'grad_norm': 0.10504746437072754, 'learning_rate': 0.0003318181818181819, 'epoch': 17.4}\n",
            "{'loss': 0.0671, 'grad_norm': 0.24452826380729675, 'learning_rate': 0.00032727272727272726, 'epoch': 17.52}\n",
            "{'loss': 0.0906, 'grad_norm': 0.40920162200927734, 'learning_rate': 0.00032272727272727276, 'epoch': 17.65}\n",
            "{'loss': 0.0765, 'grad_norm': 0.261610209941864, 'learning_rate': 0.0003181818181818182, 'epoch': 17.78}\n",
            "{'loss': 0.1133, 'grad_norm': 0.10092370212078094, 'learning_rate': 0.00031363636363636365, 'epoch': 17.9}\n",
            " 67% 141/210 [05:49<02:06,  1.83s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.57it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.48it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.03it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.64it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.31it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.67it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.0995100662112236, 'eval_f1': 0.962962962962963, 'eval_precision': 0.9701492537313433, 'eval_recall': 0.9558823529411765, 'eval_runtime': 1.6205, 'eval_samples_per_second': 167.853, 'eval_steps_per_second': 5.554, 'epoch': 17.9}\n",
            " 67% 141/210 [05:52<02:06,  1.83s/it]\n",
            "100% 9/9 [00:01<00:00,  5.93it/s]\u001b[A\n",
            "{'loss': 0.098, 'grad_norm': 0.2834756672382355, 'learning_rate': 0.0003090909090909091, 'epoch': 18.03}\n",
            "{'loss': 0.0918, 'grad_norm': 0.10812884569168091, 'learning_rate': 0.0003045454545454546, 'epoch': 18.16}\n",
            "{'loss': 0.0759, 'grad_norm': 0.3245573043823242, 'learning_rate': 0.0003, 'epoch': 18.29}\n",
            "{'loss': 0.1133, 'grad_norm': 0.12000023573637009, 'learning_rate': 0.00029545454545454547, 'epoch': 18.41}\n",
            "{'loss': 0.0979, 'grad_norm': 0.12727725505828857, 'learning_rate': 0.0002909090909090909, 'epoch': 18.54}\n",
            "{'loss': 0.1112, 'grad_norm': 0.22303448617458344, 'learning_rate': 0.00028636363636363636, 'epoch': 18.67}\n",
            "{'loss': 0.0924, 'grad_norm': 0.5310385227203369, 'learning_rate': 0.0002818181818181818, 'epoch': 18.79}\n",
            "{'loss': 0.0787, 'grad_norm': 0.08743003755807877, 'learning_rate': 0.0002772727272727273, 'epoch': 18.92}\n",
            " 71% 149/210 [06:10<01:55,  1.90s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.44it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.41it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.10it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.68it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.35it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.66it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.10006842017173767, 'eval_f1': 0.9562043795620438, 'eval_precision': 0.9492753623188406, 'eval_recall': 0.9632352941176471, 'eval_runtime': 1.6209, 'eval_samples_per_second': 167.811, 'eval_steps_per_second': 5.553, 'epoch': 18.92}\n",
            " 71% 149/210 [06:12<01:55,  1.90s/it]\n",
            "100% 9/9 [00:01<00:00,  5.92it/s]\u001b[A\n",
            "{'loss': 0.0707, 'grad_norm': 0.2893044650554657, 'learning_rate': 0.00027272727272727274, 'epoch': 19.05}\n",
            "{'loss': 0.0892, 'grad_norm': 0.37306156754493713, 'learning_rate': 0.0002681818181818182, 'epoch': 19.17}\n",
            "{'loss': 0.1105, 'grad_norm': 0.3992217481136322, 'learning_rate': 0.0002636363636363636, 'epoch': 19.3}\n",
            "{'loss': 0.0803, 'grad_norm': 0.15785656869411469, 'learning_rate': 0.0002590909090909091, 'epoch': 19.43}\n",
            "{'loss': 0.115, 'grad_norm': 0.396600604057312, 'learning_rate': 0.0002545454545454545, 'epoch': 19.56}\n",
            "{'loss': 0.0973, 'grad_norm': 0.30372411012649536, 'learning_rate': 0.00025, 'epoch': 19.68}\n",
            "{'loss': 0.0935, 'grad_norm': 0.49372196197509766, 'learning_rate': 0.00024545454545454545, 'epoch': 19.81}\n",
            "{'loss': 0.0888, 'grad_norm': 0.33338692784309387, 'learning_rate': 0.00024090909090909092, 'epoch': 19.94}\n",
            " 75% 157/210 [06:30<01:43,  1.96s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.51it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.34it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.02it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.63it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.30it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.66it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.10329581797122955, 'eval_f1': 0.9591078066914498, 'eval_precision': 0.9699248120300752, 'eval_recall': 0.9485294117647058, 'eval_runtime': 1.6276, 'eval_samples_per_second': 167.12, 'eval_steps_per_second': 5.53, 'epoch': 19.94}\n",
            " 75% 157/210 [06:32<01:43,  1.96s/it]\n",
            "100% 9/9 [00:01<00:00,  5.93it/s]\u001b[A\n",
            "{'loss': 0.0932, 'grad_norm': 0.22441747784614563, 'learning_rate': 0.00023636363636363636, 'epoch': 20.06}\n",
            "{'loss': 0.0885, 'grad_norm': 0.6129594445228577, 'learning_rate': 0.00023181818181818183, 'epoch': 20.19}\n",
            "{'loss': 0.067, 'grad_norm': 0.203774094581604, 'learning_rate': 0.00022727272727272727, 'epoch': 20.32}\n",
            "{'loss': 0.1124, 'grad_norm': 0.336961567401886, 'learning_rate': 0.00022272727272727272, 'epoch': 20.44}\n",
            "{'loss': 0.0684, 'grad_norm': 0.38791072368621826, 'learning_rate': 0.00021818181818181818, 'epoch': 20.57}\n",
            "{'loss': 0.096, 'grad_norm': 0.4621911346912384, 'learning_rate': 0.00021363636363636363, 'epoch': 20.7}\n",
            "{'loss': 0.0683, 'grad_norm': 0.27476951479911804, 'learning_rate': 0.00020909090909090907, 'epoch': 20.83}\n",
            "{'loss': 0.0794, 'grad_norm': 0.2804960012435913, 'learning_rate': 0.00020454545454545457, 'epoch': 20.95}\n",
            " 79% 165/210 [06:50<01:27,  1.95s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.44it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.37it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.02it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.63it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.32it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.65it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.09828805923461914, 'eval_f1': 0.9558823529411765, 'eval_precision': 0.9558823529411765, 'eval_recall': 0.9558823529411765, 'eval_runtime': 1.6251, 'eval_samples_per_second': 167.37, 'eval_steps_per_second': 5.538, 'epoch': 20.95}\n",
            " 79% 165/210 [06:52<01:27,  1.95s/it]\n",
            "100% 9/9 [00:01<00:00,  5.94it/s]\u001b[A\n",
            "{'loss': 0.1092, 'grad_norm': 0.25994428992271423, 'learning_rate': 0.0002, 'epoch': 21.08}\n",
            "{'loss': 0.1084, 'grad_norm': 0.1823897659778595, 'learning_rate': 0.00019545454545454548, 'epoch': 21.21}\n",
            "{'loss': 0.0725, 'grad_norm': 0.1998954713344574, 'learning_rate': 0.00019090909090909092, 'epoch': 21.33}\n",
            "{'loss': 0.0807, 'grad_norm': 0.3170397877693176, 'learning_rate': 0.00018636363636363636, 'epoch': 21.46}\n",
            "{'loss': 0.0722, 'grad_norm': 0.3516240119934082, 'learning_rate': 0.00018181818181818183, 'epoch': 21.59}\n",
            "{'loss': 0.0905, 'grad_norm': 0.5870281457901001, 'learning_rate': 0.00017727272727272728, 'epoch': 21.71}\n",
            "{'loss': 0.0727, 'grad_norm': 0.20920945703983307, 'learning_rate': 0.00017272727272727272, 'epoch': 21.84}\n",
            "{'loss': 0.0688, 'grad_norm': 0.19361113011837006, 'learning_rate': 0.0001681818181818182, 'epoch': 21.97}\n",
            " 82% 173/210 [07:10<01:06,  1.80s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.51it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.44it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.07it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.68it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.34it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.66it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.0970907211303711, 'eval_f1': 0.9597069597069599, 'eval_precision': 0.9562043795620438, 'eval_recall': 0.9632352941176471, 'eval_runtime': 1.6201, 'eval_samples_per_second': 167.89, 'eval_steps_per_second': 5.555, 'epoch': 21.97}\n",
            " 82% 173/210 [07:12<01:06,  1.80s/it]\n",
            "100% 9/9 [00:01<00:00,  5.93it/s]\u001b[A\n",
            "{'loss': 0.1014, 'grad_norm': 0.13706178963184357, 'learning_rate': 0.00016363636363636363, 'epoch': 22.1}\n",
            "{'loss': 0.0665, 'grad_norm': 0.08380495756864548, 'learning_rate': 0.0001590909090909091, 'epoch': 22.22}\n",
            "{'loss': 0.0717, 'grad_norm': 0.20024149119853973, 'learning_rate': 0.00015454545454545454, 'epoch': 22.35}\n",
            "{'loss': 0.0967, 'grad_norm': 0.4815191924571991, 'learning_rate': 0.00015, 'epoch': 22.48}\n",
            "{'loss': 0.0945, 'grad_norm': 0.4598430395126343, 'learning_rate': 0.00014545454545454546, 'epoch': 22.6}\n",
            "{'loss': 0.0826, 'grad_norm': 0.13568533957004547, 'learning_rate': 0.0001409090909090909, 'epoch': 22.73}\n",
            "{'loss': 0.0761, 'grad_norm': 0.09914925694465637, 'learning_rate': 0.00013636363636363637, 'epoch': 22.86}\n",
            "{'loss': 0.0683, 'grad_norm': 0.1140485405921936, 'learning_rate': 0.0001318181818181818, 'epoch': 22.98}\n",
            " 86% 181/210 [07:30<00:54,  1.88s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.50it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.34it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.04it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.64it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.32it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.67it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.09745413810014725, 'eval_f1': 0.9558823529411765, 'eval_precision': 0.9558823529411765, 'eval_recall': 0.9558823529411765, 'eval_runtime': 1.6288, 'eval_samples_per_second': 166.998, 'eval_steps_per_second': 5.526, 'epoch': 22.98}\n",
            " 86% 181/210 [07:32<00:54,  1.88s/it]\n",
            "100% 9/9 [00:01<00:00,  5.92it/s]\u001b[A\n",
            "{'loss': 0.1023, 'grad_norm': 0.10325179994106293, 'learning_rate': 0.00012727272727272725, 'epoch': 23.11}\n",
            "{'loss': 0.0796, 'grad_norm': 0.3222244381904602, 'learning_rate': 0.00012272727272727272, 'epoch': 23.24}\n",
            "{'loss': 0.0812, 'grad_norm': 0.11558414250612259, 'learning_rate': 0.00011818181818181818, 'epoch': 23.37}\n",
            "{'loss': 0.098, 'grad_norm': 0.3471602499485016, 'learning_rate': 0.00011363636363636364, 'epoch': 23.49}\n",
            "{'loss': 0.0686, 'grad_norm': 0.0925133004784584, 'learning_rate': 0.00010909090909090909, 'epoch': 23.62}\n",
            "{'loss': 0.0786, 'grad_norm': 0.2878182530403137, 'learning_rate': 0.00010454545454545454, 'epoch': 23.75}\n",
            "{'loss': 0.0572, 'grad_norm': 0.15773369371891022, 'learning_rate': 0.0001, 'epoch': 23.87}\n",
            "{'loss': 0.0905, 'grad_norm': 0.18612565100193024, 'learning_rate': 9.545454545454546e-05, 'epoch': 24.0}\n",
            " 90% 189/210 [07:50<00:39,  1.88s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.50it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.45it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.12it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.68it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.33it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.64it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.09768495708703995, 'eval_f1': 0.9558823529411765, 'eval_precision': 0.9558823529411765, 'eval_recall': 0.9558823529411765, 'eval_runtime': 1.6207, 'eval_samples_per_second': 167.83, 'eval_steps_per_second': 5.553, 'epoch': 24.0}\n",
            " 90% 189/210 [07:52<00:39,  1.88s/it]\n",
            "100% 9/9 [00:01<00:00,  5.90it/s]\u001b[A\n",
            "{'loss': 0.0729, 'grad_norm': 0.13271504640579224, 'learning_rate': 9.090909090909092e-05, 'epoch': 24.13}\n",
            "{'loss': 0.0637, 'grad_norm': 0.0801769345998764, 'learning_rate': 8.636363636363636e-05, 'epoch': 24.25}\n",
            "{'loss': 0.0787, 'grad_norm': 0.18088744580745697, 'learning_rate': 8.181818181818182e-05, 'epoch': 24.38}\n",
            "{'loss': 0.0845, 'grad_norm': 0.144302636384964, 'learning_rate': 7.727272727272727e-05, 'epoch': 24.51}\n",
            "{'loss': 0.0614, 'grad_norm': 0.08522885292768478, 'learning_rate': 7.272727272727273e-05, 'epoch': 24.63}\n",
            "{'loss': 0.095, 'grad_norm': 0.12099871784448624, 'learning_rate': 6.818181818181818e-05, 'epoch': 24.76}\n",
            "{'loss': 0.0918, 'grad_norm': 0.2736910283565521, 'learning_rate': 6.363636363636363e-05, 'epoch': 24.89}\n",
            " 93% 196/210 [08:09<00:27,  1.97s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.51it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.42it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.07it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.65it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.33it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.67it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.09859059005975723, 'eval_f1': 0.9558823529411765, 'eval_precision': 0.9558823529411765, 'eval_recall': 0.9558823529411765, 'eval_runtime': 1.6189, 'eval_samples_per_second': 168.015, 'eval_steps_per_second': 5.559, 'epoch': 24.89}\n",
            " 93% 196/210 [08:12<00:27,  1.97s/it]\n",
            "100% 9/9 [00:01<00:00,  5.94it/s]\u001b[A\n",
            "{'loss': 0.0806, 'grad_norm': 0.1843782514333725, 'learning_rate': 5.909090909090909e-05, 'epoch': 25.02}\n",
            "{'loss': 0.061, 'grad_norm': 0.106483593583107, 'learning_rate': 5.4545454545454546e-05, 'epoch': 25.14}\n",
            "{'loss': 0.0959, 'grad_norm': 0.23523905873298645, 'learning_rate': 5e-05, 'epoch': 25.27}\n",
            "{'loss': 0.0745, 'grad_norm': 0.18138480186462402, 'learning_rate': 4.545454545454546e-05, 'epoch': 25.4}\n",
            "{'loss': 0.0897, 'grad_norm': 0.0716935247182846, 'learning_rate': 4.090909090909091e-05, 'epoch': 25.52}\n",
            "{'loss': 0.0553, 'grad_norm': 0.08843346685171127, 'learning_rate': 3.6363636363636364e-05, 'epoch': 25.65}\n",
            "{'loss': 0.0978, 'grad_norm': 0.10681048035621643, 'learning_rate': 3.1818181818181814e-05, 'epoch': 25.78}\n",
            "{'loss': 0.0648, 'grad_norm': 0.1081952452659607, 'learning_rate': 2.7272727272727273e-05, 'epoch': 25.9}\n",
            " 97% 204/210 [08:29<00:11,  1.89s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.57it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.50it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.10it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.65it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.31it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.64it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.09902331233024597, 'eval_f1': 0.9558823529411765, 'eval_precision': 0.9558823529411765, 'eval_recall': 0.9558823529411765, 'eval_runtime': 1.6176, 'eval_samples_per_second': 168.151, 'eval_steps_per_second': 5.564, 'epoch': 25.9}\n",
            " 97% 204/210 [08:32<00:11,  1.89s/it]\n",
            "100% 9/9 [00:01<00:00,  5.93it/s]\u001b[A\n",
            "{'loss': 0.0891, 'grad_norm': 0.3026517331600189, 'learning_rate': 2.272727272727273e-05, 'epoch': 26.03}\n",
            "{'loss': 0.0895, 'grad_norm': 0.289607435464859, 'learning_rate': 1.8181818181818182e-05, 'epoch': 26.16}\n",
            "{'loss': 0.1017, 'grad_norm': 0.14370140433311462, 'learning_rate': 1.3636363636363637e-05, 'epoch': 26.29}\n",
            "{'loss': 0.0657, 'grad_norm': 0.07077178359031677, 'learning_rate': 9.090909090909091e-06, 'epoch': 26.41}\n",
            "{'loss': 0.0605, 'grad_norm': 0.20104433596134186, 'learning_rate': 4.5454545454545455e-06, 'epoch': 26.54}\n",
            "{'loss': 0.0636, 'grad_norm': 0.14605455100536346, 'learning_rate': 0.0, 'epoch': 26.67}\n",
            "100% 210/210 [08:46<00:00,  2.01s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00,  7.57it/s]\u001b[A\n",
            " 33% 3/9 [00:00<00:00,  6.49it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  5.10it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  4.68it/s]\u001b[A\n",
            " 67% 6/9 [00:01<00:00,  5.32it/s]\u001b[A\n",
            " 78% 7/9 [00:01<00:00,  5.68it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.09919002652168274, 'eval_f1': 0.9558823529411765, 'eval_precision': 0.9558823529411765, 'eval_recall': 0.9558823529411765, 'eval_runtime': 1.6128, 'eval_samples_per_second': 168.647, 'eval_steps_per_second': 5.58, 'epoch': 26.67}\n",
            "100% 210/210 [08:47<00:00,  2.01s/it]\n",
            "100% 9/9 [00:01<00:00,  5.99it/s]\u001b[A\n",
            "{'train_runtime': 532.212, 'train_samples_per_second': 112.737, 'train_steps_per_second': 0.395, 'train_loss': 0.21790055921744733, 'epoch': 26.67}\n",
            "100% 210/210 [08:52<00:00,  2.53s/it]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        eval/f1 ▁▃▄▅▆▆▇▇▇█████▇████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▇▆▅▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/precision ▂▁▃▄▅▅▅▇▆▇▇█▇▇▇███▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/recall ▁█▇▇▇▇█▆███▇████▇▇▇▇▇▇▇▇▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▁▁▂▃▃▄▄▄▅██▆▆▆▇▇▇▇▇██▇█▇▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ██▇▆▆▄▅▅▄▁▁▂▃▃▂▂▂▂▂▁▁▂▁▂▂▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ██▇▆▆▄▅▅▄▁▁▂▃▃▂▂▂▂▂▁▁▂▁▂▂▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                train/grad_norm ▄▆▆▃▄▄▃▃▃▂▄█▄█▂▁▃▂▁▂▅▂▂▂▂▂▂▁▂▄▃▂▂▄▁▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇████▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ██▇▇▆▆▅▅▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        eval/f1 0.95588\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.09919\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 eval/precision 0.95588\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    eval/recall 0.95588\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 1.6128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 168.647\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 5.58\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 26.67\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 210\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                train/grad_norm 0.14605\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.0636\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.2179\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 532.212\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 112.737\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.395\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbrisk-haze-114\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/master_thesis_johan/master_thesis_johan/runs/nqbnkero\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/master_thesis_johan/master_thesis_johan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240416_220033-nqbnkero/logs\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}