{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkMyrQSMHNXn",
        "outputId": "84c3e510-c0ec-4ab1-b9b4-cada503fec72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'master_thesis'...\n",
            "remote: Enumerating objects: 145, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 145 (delta 63), reused 116 (delta 34), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (145/145), 3.33 MiB | 2.66 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Yuhang-Zhu-nlp/master_thesis.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrL-GRZxLOJi",
        "outputId": "29c45945-42dd-4c3c-efe9-83f27c648cd8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m749.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.29.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python master_thesis/train/train.py \\\n",
        "            --pos_path_train '/content/master_thesis/data/en_train_fut_pos.json' \\\n",
        "            --neg_path_train '/content/master_thesis/data/en_train_fut_neg.json' \\\n",
        "            --pos_path_dev '/content/master_thesis/data/en_dev_fut_pos.json' \\\n",
        "            --neg_path_dev '/content/master_thesis/data/en_dev_fut_neg.json' \\\n",
        "            --model_name 'en_bert' \\\n",
        "            --pool_method 'mean' \\\n",
        "            --learning_rate 5e-4 \\\n",
        "            --weight_decay 0.01 \\\n",
        "            --batch_size_train 32 \\\n",
        "            --batch_size_valid 32 \\\n",
        "            --epoch 8 \\\n",
        "            --warmup_steps 100 \\\n",
        "            --checkpoints_dir '/content/'\\\n",
        "            --output_dir '/content/en.pt'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCX-ReP8Ho8V",
        "outputId": "a1a50a5a-24c0-47f5-fbe3-567889d588b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-10 00:05:56.209922: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-10 00:05:56.209980: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-10 00:05:56.211437: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-10 00:05:57.426701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "tokenizer_config.json: 100% 49.0/49.0 [00:00<00:00, 255kB/s]\n",
            "vocab.txt: 100% 213k/213k [00:00<00:00, 1.30MB/s]\n",
            "tokenizer.json: 100% 436k/436k [00:00<00:00, 61.0MB/s]\n",
            "config.json: 100% 762/762 [00:00<00:00, 4.09MB/s]\n",
            "model.safetensors: 100% 1.34G/1.34G [00:08<00:00, 155MB/s] \n",
            "Generating pos split: 1000 examples [00:00, 51901.35 examples/s]\n",
            "Generating neg split: 20092 examples [00:00, 406458.99 examples/s]\n",
            "Generating pos split: 136 examples [00:00, 80728.18 examples/s]\n",
            "Generating neg split: 2982 examples [00:00, 736770.41 examples/s]\n",
            "english_bert(\n",
            "  (_classfier_module__bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 1024)\n",
            "      (token_type_embeddings): Embedding(2, 1024)\n",
            "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-23): 24 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (_classfier_module__classifier_head): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "    (1): Linear(in_features=2048, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "size of training set: 2000\n",
            "size of validation set: 272\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "{'loss': 0.6914, 'grad_norm': 0.4580536186695099, 'learning_rate': 5e-06, 'epoch': 0.13}\n",
            "{'loss': 0.6905, 'grad_norm': 0.49014773964881897, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
            "{'loss': 0.6873, 'grad_norm': 0.5350888967514038, 'learning_rate': 1.5e-05, 'epoch': 0.38}\n",
            "{'loss': 0.6846, 'grad_norm': 0.4935040771961212, 'learning_rate': 2e-05, 'epoch': 0.51}\n",
            "{'loss': 0.6857, 'grad_norm': 0.4452662765979767, 'learning_rate': 2.5e-05, 'epoch': 0.63}\n",
            "{'loss': 0.6698, 'grad_norm': 0.6189121603965759, 'learning_rate': 3e-05, 'epoch': 0.76}\n",
            "{'loss': 0.6684, 'grad_norm': 0.5142675638198853, 'learning_rate': 3.5000000000000004e-05, 'epoch': 0.89}\n",
            " 12% 7/56 [00:09<01:00,  1.23s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00, 11.55it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  7.81it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  7.47it/s]\u001b[A\n",
            " 78% 7/9 [00:00<00:00,  8.83it/s]\u001b[A\n",
            " 89% 8/9 [00:00<00:00,  8.31it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                  \n",
            "\u001b[A{'eval_loss': 0.65216463804245, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 1.12, 'eval_samples_per_second': 242.865, 'eval_steps_per_second': 8.036, 'epoch': 0.89}\n",
            " 12% 7/56 [00:11<01:00,  1.23s/it]\n",
            "100% 9/9 [00:01<00:00,  8.31it/s]\u001b[A\n",
            "{'loss': 0.6626, 'grad_norm': 0.5598297119140625, 'learning_rate': 4e-05, 'epoch': 1.02}\n",
            "{'loss': 0.6621, 'grad_norm': 0.5417330861091614, 'learning_rate': 4.4999999999999996e-05, 'epoch': 1.14}\n",
            "{'loss': 0.6533, 'grad_norm': 0.6016831398010254, 'learning_rate': 5e-05, 'epoch': 1.27}\n",
            "{'loss': 0.647, 'grad_norm': 0.4272368550300598, 'learning_rate': 5.5e-05, 'epoch': 1.4}\n",
            "{'loss': 0.6225, 'grad_norm': 0.5149142146110535, 'learning_rate': 6e-05, 'epoch': 1.52}\n",
            "{'loss': 0.6143, 'grad_norm': 0.4360499083995819, 'learning_rate': 6.500000000000001e-05, 'epoch': 1.65}\n",
            "{'loss': 0.62, 'grad_norm': 0.38978323340415955, 'learning_rate': 7.000000000000001e-05, 'epoch': 1.78}\n",
            "{'loss': 0.5805, 'grad_norm': 0.4775916337966919, 'learning_rate': 7.5e-05, 'epoch': 1.9}\n",
            " 27% 15/56 [00:25<00:51,  1.25s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00, 11.36it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  7.99it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  7.62it/s]\u001b[A\n",
            " 78% 7/9 [00:00<00:00,  8.72it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.5657037496566772, 'eval_f1': 0.6138613861386139, 'eval_precision': 0.9393939393939394, 'eval_recall': 0.45588235294117646, 'eval_runtime': 1.099, 'eval_samples_per_second': 247.507, 'eval_steps_per_second': 8.19, 'epoch': 1.9}\n",
            " 27% 15/56 [00:27<00:51,  1.25s/it]\n",
            "100% 9/9 [00:01<00:00,  8.48it/s]\u001b[A\n",
            "{'loss': 0.5871, 'grad_norm': 0.4532478153705597, 'learning_rate': 8e-05, 'epoch': 2.03}\n",
            "{'loss': 0.5992, 'grad_norm': 0.5145354270935059, 'learning_rate': 8.5e-05, 'epoch': 2.16}\n",
            "{'loss': 0.562, 'grad_norm': 0.4020096957683563, 'learning_rate': 8.999999999999999e-05, 'epoch': 2.29}\n",
            "{'loss': 0.5499, 'grad_norm': 0.48225247859954834, 'learning_rate': 9.5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.5516, 'grad_norm': 0.3697797954082489, 'learning_rate': 0.0001, 'epoch': 2.54}\n",
            "{'loss': 0.5264, 'grad_norm': 0.3707670271396637, 'learning_rate': 0.000105, 'epoch': 2.67}\n",
            "{'loss': 0.5367, 'grad_norm': 0.4408663809299469, 'learning_rate': 0.00011, 'epoch': 2.79}\n",
            "{'loss': 0.5318, 'grad_norm': 0.4005548357963562, 'learning_rate': 0.000115, 'epoch': 2.92}\n",
            " 41% 23/56 [00:42<00:45,  1.37s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00, 11.38it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  8.09it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  7.72it/s]\u001b[A\n",
            " 78% 7/9 [00:00<00:00,  8.86it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.46740859746932983, 'eval_f1': 0.7330316742081449, 'eval_precision': 0.9529411764705882, 'eval_recall': 0.5955882352941176, 'eval_runtime': 1.0906, 'eval_samples_per_second': 249.407, 'eval_steps_per_second': 8.252, 'epoch': 2.92}\n",
            " 41% 23/56 [00:44<00:45,  1.37s/it]\n",
            "100% 9/9 [00:01<00:00,  8.57it/s]\u001b[A\n",
            "{'loss': 0.5119, 'grad_norm': 0.539828896522522, 'learning_rate': 0.00012, 'epoch': 3.05}\n",
            "{'loss': 0.49, 'grad_norm': 0.3590488135814667, 'learning_rate': 0.000125, 'epoch': 3.17}\n",
            "{'loss': 0.5062, 'grad_norm': 0.4487134516239166, 'learning_rate': 0.00013000000000000002, 'epoch': 3.3}\n",
            "{'loss': 0.4606, 'grad_norm': 0.36667507886886597, 'learning_rate': 0.000135, 'epoch': 3.43}\n",
            "{'loss': 0.4847, 'grad_norm': 0.4649806022644043, 'learning_rate': 0.00014000000000000001, 'epoch': 3.56}\n",
            "{'loss': 0.4523, 'grad_norm': 0.3414170742034912, 'learning_rate': 0.000145, 'epoch': 3.68}\n",
            "{'loss': 0.4079, 'grad_norm': 0.3996966481208801, 'learning_rate': 0.00015, 'epoch': 3.81}\n",
            "{'loss': 0.4677, 'grad_norm': 0.3319576382637024, 'learning_rate': 0.000155, 'epoch': 3.94}\n",
            " 55% 31/56 [00:59<00:34,  1.36s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00, 11.43it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  8.01it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  7.66it/s]\u001b[A\n",
            " 78% 7/9 [00:00<00:00,  8.77it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.38060110807418823, 'eval_f1': 0.8421052631578947, 'eval_precision': 0.9369369369369369, 'eval_recall': 0.7647058823529411, 'eval_runtime': 1.0929, 'eval_samples_per_second': 248.887, 'eval_steps_per_second': 8.235, 'epoch': 3.94}\n",
            " 55% 31/56 [01:00<00:34,  1.36s/it]\n",
            "100% 9/9 [00:01<00:00,  8.56it/s]\u001b[A\n",
            "{'loss': 0.3786, 'grad_norm': 0.46376466751098633, 'learning_rate': 0.00016, 'epoch': 4.06}\n",
            "{'loss': 0.4146, 'grad_norm': 0.335618793964386, 'learning_rate': 0.000165, 'epoch': 4.19}\n",
            "{'loss': 0.3945, 'grad_norm': 0.3977920413017273, 'learning_rate': 0.00017, 'epoch': 4.32}\n",
            "{'loss': 0.421, 'grad_norm': 0.29912543296813965, 'learning_rate': 0.000175, 'epoch': 4.44}\n",
            "{'loss': 0.3962, 'grad_norm': 0.3296656012535095, 'learning_rate': 0.00017999999999999998, 'epoch': 4.57}\n",
            "{'loss': 0.3787, 'grad_norm': 0.45754608511924744, 'learning_rate': 0.000185, 'epoch': 4.7}\n",
            "{'loss': 0.3708, 'grad_norm': 0.2910192310810089, 'learning_rate': 0.00019, 'epoch': 4.83}\n",
            "{'loss': 0.3761, 'grad_norm': 0.45009103417396545, 'learning_rate': 0.00019500000000000002, 'epoch': 4.95}\n",
            " 70% 39/56 [01:19<00:24,  1.46s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00, 11.32it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  7.96it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  7.61it/s]\u001b[A\n",
            " 78% 7/9 [00:00<00:00,  8.92it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.3163653612136841, 'eval_f1': 0.8793774319066149, 'eval_precision': 0.9338842975206612, 'eval_recall': 0.8308823529411765, 'eval_runtime': 1.0953, 'eval_samples_per_second': 248.332, 'eval_steps_per_second': 8.217, 'epoch': 4.95}\n",
            " 70% 39/56 [01:21<00:24,  1.46s/it]\n",
            "100% 9/9 [00:01<00:00,  8.59it/s]\u001b[A\n",
            "{'loss': 0.3549, 'grad_norm': 0.35230153799057007, 'learning_rate': 0.0002, 'epoch': 5.08}\n",
            "{'loss': 0.3417, 'grad_norm': 0.3286815881729126, 'learning_rate': 0.000205, 'epoch': 5.21}\n",
            "{'loss': 0.3677, 'grad_norm': 0.2690568268299103, 'learning_rate': 0.00021, 'epoch': 5.33}\n",
            "{'loss': 0.3326, 'grad_norm': 0.30812379717826843, 'learning_rate': 0.000215, 'epoch': 5.46}\n",
            "{'loss': 0.347, 'grad_norm': 0.27394604682922363, 'learning_rate': 0.00022, 'epoch': 5.59}\n",
            "{'loss': 0.322, 'grad_norm': 0.26033690571784973, 'learning_rate': 0.00022500000000000002, 'epoch': 5.71}\n",
            "{'loss': 0.3154, 'grad_norm': 0.2558613717556, 'learning_rate': 0.00023, 'epoch': 5.84}\n",
            "{'loss': 0.3423, 'grad_norm': 0.23417066037654877, 'learning_rate': 0.000235, 'epoch': 5.97}\n",
            " 84% 47/56 [01:44<00:14,  1.60s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00, 11.41it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  7.95it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  7.60it/s]\u001b[A\n",
            " 78% 7/9 [00:00<00:00,  9.05it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.2662360668182373, 'eval_f1': 0.9144981412639406, 'eval_precision': 0.924812030075188, 'eval_recall': 0.9044117647058824, 'eval_runtime': 1.0829, 'eval_samples_per_second': 251.189, 'eval_steps_per_second': 8.311, 'epoch': 5.97}\n",
            " 84% 47/56 [01:45<00:14,  1.60s/it]\n",
            "100% 9/9 [00:01<00:00,  8.70it/s]\u001b[A\n",
            "{'loss': 0.3035, 'grad_norm': 0.25929564237594604, 'learning_rate': 0.00024, 'epoch': 6.1}\n",
            "{'loss': 0.3442, 'grad_norm': 0.5825933814048767, 'learning_rate': 0.000245, 'epoch': 6.22}\n",
            "{'loss': 0.3045, 'grad_norm': 0.2133004516363144, 'learning_rate': 0.00025, 'epoch': 6.35}\n",
            "{'loss': 0.3039, 'grad_norm': 0.22470512986183167, 'learning_rate': 0.000255, 'epoch': 6.48}\n",
            "{'loss': 0.2866, 'grad_norm': 0.6497685313224792, 'learning_rate': 0.00026000000000000003, 'epoch': 6.6}\n",
            "{'loss': 0.2709, 'grad_norm': 0.48963451385498047, 'learning_rate': 0.00026500000000000004, 'epoch': 6.73}\n",
            "{'loss': 0.2719, 'grad_norm': 0.19372524321079254, 'learning_rate': 0.00027, 'epoch': 6.86}\n",
            "{'loss': 0.2925, 'grad_norm': 0.3102249503135681, 'learning_rate': 0.000275, 'epoch': 6.98}\n",
            " 98% 55/56 [02:00<00:01,  1.32s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00, 11.51it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  8.10it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  7.74it/s]\u001b[A\n",
            " 78% 7/9 [00:00<00:00,  8.96it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.23557129502296448, 'eval_f1': 0.9314079422382672, 'eval_precision': 0.9148936170212766, 'eval_recall': 0.9485294117647058, 'eval_runtime': 1.0839, 'eval_samples_per_second': 250.947, 'eval_steps_per_second': 8.303, 'epoch': 6.98}\n",
            " 98% 55/56 [02:02<00:01,  1.32s/it]\n",
            "100% 9/9 [00:01<00:00,  8.63it/s]\u001b[A\n",
            "{'loss': 0.2341, 'grad_norm': 0.2115936577320099, 'learning_rate': 0.00028000000000000003, 'epoch': 7.11}\n",
            "100% 56/56 [02:10<00:00,  3.65s/it]\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:00<00:00, 11.42it/s]\u001b[A\n",
            " 44% 4/9 [00:00<00:00,  8.09it/s]\u001b[A\n",
            " 56% 5/9 [00:00<00:00,  7.73it/s]\u001b[A\n",
            " 78% 7/9 [00:00<00:00,  8.99it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.23760312795639038, 'eval_f1': 0.9428571428571428, 'eval_precision': 0.9166666666666666, 'eval_recall': 0.9705882352941176, 'eval_runtime': 1.0819, 'eval_samples_per_second': 251.411, 'eval_steps_per_second': 8.319, 'epoch': 7.11}\n",
            "100% 56/56 [02:11<00:00,  3.65s/it]\n",
            "100% 9/9 [00:01<00:00,  8.60it/s]\u001b[A\n",
            "{'train_runtime': 138.215, 'train_samples_per_second': 115.762, 'train_steps_per_second': 0.405, 'train_loss': 0.4737912392509835, 'epoch': 7.11}\n",
            "100% 56/56 [02:18<00:00,  2.47s/it]\n"
          ]
        }
      ]
    }
  ]
}